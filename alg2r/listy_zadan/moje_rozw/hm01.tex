\documentclass{article}

\usepackage{../../../notatki}

\title{\large Algebra 2R\smallskip\\ \textbf{Problem List 1}}
\author{\normalsize Weronika Jakimowicz}
\date{~~~}

\color{black}
\pagecolor{white}

\begin{document}
\maketitle
\thispagestyle{empty}

\subsection*{EXERCISE 1.}
\emph{Proof that $\C=\R[z]$ for every complex number $z\in \C\setminus\R$.}
\bigskip

To begin with, let us take any $z\in\C\setminus\R$ such that $z=ai$ for some $a\in\R$. We have that
$$\R[z]=\{f(z)\;:\;f\in\R[X]\}.$$

Let $I=(X^2+a^2)\normalsubgroup\R[X]$ be an ideal of $\R[X]$ generated by a polynomial with no real roots. We know that $\R[X]/I\cong \C$. 

This is because $\R$ is a field and so $\R[X]$ is an euclidean domain: if we take any $f\in\R[X]$ then we can write it as $f=v(X^2+a^2)+w$, where $w$ is of degree $0$ or $1$ ($<def(X^2+a^2)$) and so $f$ in $\R[X]/I$ is represented only by $w$. Now it is quite easy to map polynomials with real coefficients and maximal degree $1$ to $\C$, for example $f:\R[X]/I\to\C$ such that $f(aX+b)=ai+b$. Therefore $\R[X]/I\cong \C$.

Consider the evaluation homomorphism $\phi_z$ which maps $\R[X]\ni w\mapsto w(z)\in\R[z]$. We can see that $\ker(\phi_z)=(X^2+a^2)=I$. Therefore, by the fundamental theorem on ring homomorphism we have an isomorphism
$$f:Im(\phi_z)=\R[z]\to \R[X]/ker(\phi_z)=\R[X]/I$$
and as mentioned above, $\R[X]/I\cong\C$. Hence, $\R[z]\cong\C$.

\subsection*{EXERCISE 2.}
\emph{Assume that $K\subset L$ are fields and $a,b\in L$. For a rational function $f(X)\in K(X)$ define $f(a)$ as ${g(a)\over h(a)}$, where $g,h\in K[X]$, $f=\frac gh$ and $h(a)\neq 0$, provided such $g,h$ exist. If not, $f(a)$ is undetermined. Prove that}

\begin{center}
    {\color{red}I know I shouldn't do this but I wanted to know if the diagram I drew in (c) is a correct solution. If not I have (a) as a more reasonable backup to get at least some points c:}
\end{center}

\emph{(a) if $f(X)\in K(X)$ and $f(a)$ is defined, then $f(a)$ is determined uniquely (does not depend on the choice of $g, h$)}
\bigskip

Suppose by contradiction that $f(a)$ depends on which $g,h$ we choose. That means that there exist $g,h, g',h'\in K[X], h(a)\neq 0, h'(a)$ such that $f={g\over h}={g'\over h'}$ but ${g(a)\over h(a)}+c= {g'(a)\over h'(a)}$, where $c\in L\setminus\{0\}$. 

From $f={g\over h}={g'\over h'}$ we get that $g\cdot h'=g'\cdot h$ and in particular
\begin{align*}
    (gh')(a)&=(g'h)(a)\\
    g(a)h'(a)&=g'(a)h(a)\\
    g(a)h'(a)-g'(a)h(a)=0
\end{align*}

From the assumption that $f(a)$ depends on the choice of polynomials we get that 
\begin{align*}
    {g'(a)\over h'(a)}&={g(a)\over h(a)}+c\\
    g'(a)h(a)&=g(a)h'(a)+ch'(a)\\
    g'(a)h(a)-g(a)h'(a)&=ch'(a)\neq 0
\end{align*}
Which is a contradiction because $c\neq 0$, $h'(a)\neq 0$ and we have no zero divisors.
\smallskip

\emph{(c) $K(a, b)=(K(a))(b)$}
\smallskip

Let 
$$I_{ab}=I((a, b)/K[x, y])$$
$$I_a=I(a/(K[y])[x])$$
$$I_b=I(b/(K(a))(y))$$
and $j_a,j_b, j_{ab}$ are quotient functions defined as below. We know that $ker(j_a)=I_a$, $ker(j_b)=I_b$ and $ker(j_{ab})=I_{ab}$. Let $\phi_a$ be an evaluation function that substitutes only one variable:
$$\phi_a:K(x, y)\to (K(a))(y)$$
$$\phi_a(f(x, y))=f(a, y)$$
that is $\phi_a$ returns a rational function with changed coefficients. $\phi_b, \phi_{ab}$ are defined as evaluation functions without such modifications.

\begin{center}\begin{tikzcd}
    K(x, y)/I_{a, b} \arrow[d, "\cong"]  &  K(x, y) \arrow[l, "j_{ab}" above] \arrow[r, "j_a"] \arrow[dl, "\phi_{ab}"] \arrow[to=2-3, "\phi_a"] \arrow[to=4-3, "\psi", bend right=20] &  K(x, y)/I_{a} \arrow[d, "\cong"]\\
    K(a, b)        &                & (K(a))(y) \arrow[d, "j_b"] \arrow[to=4-3, bend left=60, "\phi_b"]\\
    & & (K(a))(y)/I_b \arrow[d, "\cong"]\\
    & & (K(a))(b) \arrow[to=2-1, leftrightarrow, dashed, bend left=20, "f"]
\end{tikzcd}\end{center}

Function $\psi$ is a ring homomorphism defined as composition of $\phi_a$ and $\phi_b$:
$$\psi:K(x, y)\to(K(a))(y)$$
$$\psi=\phi_b\circ\phi_a$$

For $f$ to be an isomorphism
$$f:(K(a))(b)\to K(a, b)$$
we need to show that $ker(\phi_{ab})=\ker(\psi)$ because then
\begin{center}
    \begin{tikzcd}[row sep=large]
        & K(x, y)/ker(\phi_{ab}) = K(x, y)/ker(\psi) \arrow[dl, "\cong" above] \arrow[dr, "\cong"] &\\
        K(a, b) \arrow[rr, leftrightarrow, dashed, "\cong" above] & & (K(a))(b)
    \end{tikzcd}
\end{center}

$ker(\phi_{ab})=ker(\psi)$

$\subseteq$

$f\in ker(\phi_{ab})$ means that $f(a, b)=0$. That is, either of the following is true for any $x, y\in K$

\indent $f(a, b)=0$ this directly implies that $f\in ker(\psi)$.

\indent $f(a, y)=0$ the same as above.

\indent $f(x, b)=0$ we know that for any $x\in K$ $f(x, b)=0$ then for $x=a$ this is also true and so $f(a, b)=0$ and $f\in ker(\psi)$.

$\supseteq$

$f\in ker(\psi)$ means that $f(a, b)=0$ or $f(a, y)=0$. This means that $f\in ker(\phi_{ab})$.

Therefore, there exists an isomorphism $K(a, b)\cong (K(a))(b)$.

\subsection*{EXERCISE 3.}
\emph{Assume that $K\subseteq L$ are fields and $f_1,...,f_m\in K[X_1,...,X_n]$ have degree $1$.}

\emph{(a) Prove that if the system of equations $f_1=...=f_m=0$ has a solution in $L$ then it has a solution in $K$. (hint: use linear algebra).}
\bigskip

%\begin{center}
% Take $\overline a=(a_1,..., a_n)$ be a solution from $L$. We have
% $$0=f_i(\overline a)=\sum\limits_{1\leq k\leq n}b_{i, k}a_k.$$
% This is a linear combination of elements from $L$ and therefore we have three possibilities:

% \indent 1. $(\forall\;k=1,...,n)\;b_{i,k}=0$ and so this equation does not influence the remaining $(m-1)$ polynomials. From those remaining polynomials either one has non-zero coefficients $b_{j, k}$ (in this case we jump to case 2 or 3) or all polynomials from the set of equations are trivial and any sequence from $K$ is a solution.

% \indent 2. $(\forall\;k=1,...,n)\;a_k=0$ and hence $\overline a=(0,...,0)\in K^n$ is a solution.

% \indent 3. $a_k$ and $b_{i, k}$ are linearly dependent and
% \begin{align*}
%     0&=\sum\limits_{1\leq k\leq n}a_kb_{i, k}\\
%     0&=a_1b_{i, 1}+\sum\limits_{2\leq k\leq n}a_kb_{i, k}\\
%     -a_1b_{i, 1}&=\sum\limits_{2\leq k\leq n}a_kb_{i, k}\\
%     b_{i, 1}&=\sum\limits_{2\leq k\leq n}[a_k(-a_1)^{-1}]b_{i, k}
% \end{align*}
% The last operation is permitted because we are inside a field and $-a_1$ is non-zero, therefore it has a multiplicative inverse. We have that 
% $$\sum\limits_{2\leq k\leq n}[a_k(-a_1)^{-1}]b_{i, k}\in K$$
% and so $a_k(-a_1)^{-1}\in K\implies a_1,a_k\in K$.

% \proofend
%\end{center}

We are working on linear equations, therefore we can construct a matrix that stores the same information as the system of equations $f_1=...=f_m$. Let
$$f_i=\sum\limits_{1\leq k\leq n}b_{i, k}X_k+c_i$$
for $i=1,...,m$. The matrix representation of this system of equations is:
$$\begin{bmatrix}
    b_{1,1} & b_{1, 2} & b_{1, 3} &... &b_{1, n-1} & b_{1, n}\\
    b_{2,1} & b_{2, 2} & b_{2, 3} &... &b_{2, n-1} & b_{2, n}\\
    ...     &   ...    & ...      &... & ...       & ...\\
    b_{m,1} & b_{m, 2} & b_{m, 3} &... &b_{m, n-1} & b_{m, n}
\end{bmatrix}\begin{bmatrix}
    a_1\\a_2\\a_3\\...\\a_n
\end{bmatrix}=\begin{bmatrix}
    c_1\\c_2\\c_3\\...\\c_m
\end{bmatrix}.$$
Using Gaussian algorithm, we can create an upper triangular matrix with coefficients that are linear combinations of elements from $K$ and thus are themselves in $K$.

If $m\leq n$, then let
$$\begin{bmatrix}
    \alpha_{1, 1}&\alpha_{1, 2}&\alpha_{1, 3}&...&...&...&\alpha_{1, n-1}&\alpha_{1, n}\\
    0&\alpha_{2, 2}&\alpha_{2, 3}&...&...&...&\alpha_{2, n-1}&\alpha_{2, n}\\
    ...     &   ...    & ...      &...&...&... & ...       & ...\\
    0&0&0&...&\alpha_{m, m}&...&\alpha_{m, n-1}&\alpha_{m, n}
\end{bmatrix}=\begin{bmatrix}
    a_1\\a_2\\a_3\\...\\a_n
\end{bmatrix}=\begin{bmatrix}
    \gamma_1\\\gamma_2\\\gamma_3\\...\\\gamma_m
\end{bmatrix}$$
be the result of Gaussian elimination of the matrix above. Because Gaussian elimination returns a matrix with elements that are linear combinations of the elements of the original matrix, we have that $b_{i, k}, \gamma_i\in K$.

The solution would be found by backwards substitution. We could take $a_{m+1},a_{m+2},...,a_n=0\in K$ then
$$\gamma_m=\alpha_{m, m}a_m+\alpha_{m, m+1}a_{m+1}+...+\alpha_{m, n}a_n=\alpha_{m, m}a_m$$
$$a_m=(\alpha_{m, m})^{-1}\gamma_m\in K$$
Then
\begin{align*}
    \gamma_{m-1}&=\alpha_{m-1, m-1}a_{m-1}+\alpha_{m-1, m}a_m+\alpha_{m-1, m+1}a_{m+1}+...+\alpha_{m-1, n}a_n=\\
    &=\alpha_{m-1,m}a_{m-1}+\alpha_{m-1,m}(\alpha_{m,m})^{-1}\gamma_m
\end{align*}
$$a_{m-1}=(\alpha_{m-1,m})^{-1}(\gamma_{m-1}-\alpha_{m-1,m}(\alpha_{m,m})^{-1}\gamma_m)\in K$$
And so on. We know from linear algebra that this will work.

If $m>n$, then the upper triangular matrix would look like this:
$$\begin{bmatrix}
    \alpha_{1, 1}&\alpha_{1, 2}&\alpha_{1, 3}&...&...&...&\alpha_{1, n-1}&\alpha_{1, n}\\
    0&\alpha_{2, 2}&\alpha_{2, 3}&...&...&...&\alpha_{2, n-1}&\alpha_{2, n}\\
    ...     &   ...    & ...      &...&...&... & ...       & ...\\
    0&0&0&...&0&...&0&\alpha_{m, m}\\
    0&0&0&...&0&...&0&0\\
    ...     &   ...    & ...      &...&...&... & ...       & ...\\
    0&0&0&...&0&...&0&0\\
\end{bmatrix}=\begin{bmatrix}
    a_1\\a_2\\a_3\\...\\a_n
\end{bmatrix}=\begin{bmatrix}
    \gamma_1\\\gamma_2\\\gamma_3\\...\\\gamma_n
\end{bmatrix}$$
and such a matrix can be treated the same way as before with the condition that for $i>m$ $\gamma_i=0$. Otherwise no solutions exist.

\end{document}